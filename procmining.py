# -*- coding: utf-8 -*-
"""ProcMining.ipynb

Automatically generated by Colaboratory.

# **Instal needed Libraries**
"""

!pip install django-extensions
!pip install pyparsing
!pip install graphviz
!pip install pydot
!pip install pm4py
!pip install --upgrade graphviz

"""# **Imports**"""

import pm4py
from pm4py.objects.conversion.log import converter as log_converter
from pm4py.objects.conversion.log import converter as stream_converter
from pm4py.objects.log.importer.xes import importer as xes_import
from pm4py.statistics.start_activities.log.get import get_start_activities
from pm4py.statistics.end_activities.log.get import get_end_activities
from pm4py.algo.filtering.log.end_activities import end_activities_filter
from pm4py.algo.discovery.alpha import algorithm as alpha_miner
from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner
from pm4py.visualization.petri_net import visualizer as pn_visualizer
from pm4py.visualization.heuristics_net import visualizer as hn_visualizer
from pm4py.objects.conversion.process_tree import converter as process_tree_converter
from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator
from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator
from pm4py.algo.conformance.tokenreplay import algorithm as token_replay
from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments
from pm4py.objects.petri_net.utils.align_utils import pretty_print_alignments

"""# **1. Read the event log**


"""

log = xes_import.apply('activitylog_uci_detailed_labour.xes')

"""# **2. Print to see the log structure**"""

print(log)

"""# **3. Print the number of traces**"""

print("Number of traces: ", len(log))

"""# **4. Print the number of events**"""

# convert log to event stream
event_stream = stream_converter.apply(log, variant=stream_converter.Variants.TO_EVENT_STREAM)

# Print the number of events
print("Number of events: ", len(event_stream))

"""**Unused statistics**"""

# ------------------ Log Statistics ------------------------
print('first trace length: ', len(log[0]))
print('first trace attributes: ', list(log[0].attributes.keys()))
print('first event of first trace attributes: ', list(log[0][0].keys()))
print('first trace concept name: ', log[0].attributes['concept:name'])
print('first event concept name: ', log[0][0]['concept:name'])

"""# **5. Θα εμφανίζει τα διαφορετικά events από τα οποία αποτελείται το event log**"""

for trace in log:
    for event in trace:
        print(trace.attributes['concept:name'], '\t', event['concept:name'], '\t', event['time:timestamp'])

"""# **6. start - end activities**"""

# get start activities
start_activities = get_start_activities(log)
print('Start activities: ', start_activities)

# get end activities
end_activities = get_end_activities(log)
print('End activities: ', end_activities)

"""# **7. Print in a mat case id, activity name, transition (start or complete), timestamp**"""

# Convert the log to a dataframe
dataframe = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)

# Select the desired columns from the dataframe
desired_columns = ['concept:name', 'lifecycle:transition', 'time:timestamp']
selected_dataframe = dataframe[desired_columns]

# Rename the columns for clarity
new_column_names = ['activity name', 'transition', 'timestamp']
selected_dataframe = selected_dataframe.rename(columns=dict(zip(desired_columns, new_column_names)))

# Print the selected dataframe
print(selected_dataframe)

"""# **8. filter log - keep traces with end activity 'end'**"""

# filter the log
filtered_log = end_activities_filter.apply(log, ['End'])

# Print the filtered log
print('Number of traces of filtered log: ', len(filtered_log))

"""# **9. Process discovery using various algorithms**

## **Alpha Miner**

> ### Process Discovery with alpha miner for initial log
"""

# Process Discovery with alpha miner for initial log
net, initial_marking, final_marking = alpha_miner.apply(log)

# show petri net
print('Alpha Miner PetriNet\n')
gviz = pn_visualizer.apply(net, initial_marking, final_marking)
pn_visualizer.view(gviz)

""">> #### Evaluation of alpha miner in the initial log"""

# Perform token-based replay fitness evaluation
fitness = pm4py.fitness_token_based_replay(log, net, initial_marking, final_marking)

# Perform token-based replay precision evaluation
prec = pm4py.precision_token_based_replay(log, net, initial_marking, final_marking)

# Perform generalization evaluation
gen = generalization_evaluator.apply(log, net, initial_marking, final_marking)

# Perform simplicity evaluation
simp = simplicity_evaluator.apply(net)

# Print the evaluation results
print("Fitness:", fitness)
print("Precision:", prec)
print("Generalization:", gen)
print("Simplicity:", simp)

""">> #### Conformance checking"""

# Replay fitness
replayed_traces = token_replay.apply(log, net, initial_marking, final_marking)
for trace in replayed_traces:
    print(trace)

# conformance checking - alignments
# aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking)
# pretty_print_alignments(aligned_traces)

"""> ### Process Discovery with alpha miner for filtered log"""

# Process Discovery with alpha miner for filtered log
net, initial_marking, final_marking = alpha_miner.apply(filtered_log)

# show petri net
print('Alpha Miner PetriNet\n')
gviz = pn_visualizer.apply(net, initial_marking, final_marking)
pn_visualizer.view(gviz)

""">> #### Evaluation"""

# Perform token-based replay fitness evaluation
fitness = pm4py.fitness_token_based_replay(filtered_log, net, initial_marking, final_marking)

# Perform token-based replay precision evaluation
prec = pm4py.precision_token_based_replay(filtered_log, net, initial_marking, final_marking)

# Perform generalization evaluation
gen = generalization_evaluator.apply(filtered_log, net, initial_marking, final_marking)

# Perform simplicity evaluation
simp = simplicity_evaluator.apply(net)

# Print the evaluation results
print(fitness, " | ", prec, " | ", gen, " | ", simp)

""">> #### Conformance checking"""

# Replay fitness
replayed_traces = token_replay.apply(filtered_log, net, initial_marking, final_marking)
for trace in replayed_traces:
    print(trace)

# conformance checking - alignments
# aligned_traces = alignments.apply_log(filtered_log, net, initial_marking, final_marking)
# pretty_print_alignments(aligned_traces)

"""## **Heuristics Miner**

> ### Process Discovery with heuristics miner for initial log
"""

# Process Discovery with heuristics miner for initial log
net, initial_marking, final_marking = heuristics_miner.apply(log)

# show petri net
print('Heuristics Miner PetriNet\n')
gviz = pn_visualizer.apply(net, initial_marking, final_marking)
pn_visualizer.view(gviz)

# Process Discovery with heuristic miner - graph
heu_net = heuristics_miner.apply_heu(log)

# visualize graph
print('Heuristic Miner Graph\n')
gviz = hn_visualizer.apply(heu_net)
hn_visualizer.view(gviz)

""">> #### Evaluation"""

# Perform token-based replay fitness evaluation
fitness = pm4py.fitness_token_based_replay(log, net, initial_marking, final_marking)

# Perform token-based replay precision evaluation
prec = pm4py.precision_token_based_replay(log, net, initial_marking, final_marking)

# Perform generalization evaluation
gen = generalization_evaluator.apply(log, net, initial_marking, final_marking)

# Perform simplicity evaluation
simp = simplicity_evaluator.apply(net)

# Print the evaluation results
print("Fitness:", fitness)
print("Precision:", prec)
print("Generalization:", gen)
print("Simplicity:", simp)

""">> #### Conformance Checking"""

# Replay fitness
replayed_traces = token_replay.apply(log, net, initial_marking, final_marking)
for trace in replayed_traces:
    print(trace)

# conformance checking - alignments
# aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking)
# pretty_print_alignments(aligned_traces)

"""> ### Process Discovery with heuristics miner for filtered log


"""

# Process Discovery with heuristics miner for filtered log
net, initial_marking, final_marking = heuristics_miner.apply(filtered_log)

# show petri net
print('Heuristics Miner PetriNet\n')
gviz = pn_visualizer.apply(net, initial_marking, final_marking)
pn_visualizer.view(gviz)

# Process Discovery with heuristic miner - graph
heu_net = heuristics_miner.apply_heu(filtered_log)

# visualize graph
print('Heuristic Miner Graph\n')
gviz = hn_visualizer.apply(heu_net)
hn_visualizer.view(gviz)

""">> #### Evaluation"""

# Perform token-based replay fitness evaluation
fitness = pm4py.fitness_token_based_replay(filtered_log, net, initial_marking, final_marking)

# Perform token-based replay precision evaluation
prec = pm4py.precision_token_based_replay(filtered_log, net, initial_marking, final_marking)

# Perform generalization evaluation
gen = generalization_evaluator.apply(filtered_log, net, initial_marking, final_marking)

# Perform simplicity evaluation
simp = simplicity_evaluator.apply(net)

# Print the evaluation results
print(fitness, " | ", prec, " | ", gen, " | ", simp)

""">> #### Conformance Checking"""

# Replay fitness
replayed_traces = token_replay.apply(filtered_log, net, initial_marking, final_marking)
for trace in replayed_traces:
    print(trace)

# conformance checking - alignments
# aligned_traces = alignments.apply_log(filtered_log, net, initial_marking, final_marking)
# pretty_print_alignments(aligned_traces)

"""## **Inductive Miner**

> ### Process Discovery with inductive miner for initial log
"""

# Discover process tree using inductive miner
process_tree = pm4py.discover_process_tree_inductive(log)

# Convert process tree to BPMN model
bpmn_model = pm4py.convert_to_bpmn(process_tree)

# Visualize BPMN model
pm4py.view_bpmn(bpmn_model)

# Convert process tree to Petri net
net, initial_marking, final_marking = process_tree_converter.apply(process_tree)

""">> #### Evaluation"""

# Perform token-based replay fitness evaluation
fitness = pm4py.fitness_token_based_replay(log, net, initial_marking, final_marking)

# Perform token-based replay precision evaluation
prec = pm4py.precision_token_based_replay(log, net, initial_marking, final_marking)

# Perform generalization evaluation
gen = generalization_evaluator.apply(log, net, initial_marking, final_marking)

# Perform simplicity evaluation
simp = simplicity_evaluator.apply(net)

# Print the evaluation results
print("Fitness:", fitness)
print("Precision:", prec)
print("Generalization:", gen)
print("Simplicity:", simp)

""">> #### Conformance Checking"""

# Replay fitness
replayed_traces = token_replay.apply(log, net, initial_marking, final_marking)
for trace in replayed_traces:
    print(trace)

# conformance checking - alignments
# aligned_traces = alignments.apply_log(log, net, initial_marking, final_marking)
# pretty_print_alignments(aligned_traces)

"""> ### Process Discovery with inductive miner for filtered log"""

# Discover process tree using inductive miner
process_tree = pm4py.discover_process_tree_inductive(filtered_log)

# Convert process tree to BPMN model
bpmn_model = pm4py.convert_to_bpmn(process_tree)

# Visualize BPMN model
pm4py.view_bpmn(bpmn_model)

# Convert process tree to Petri net
net, initial_marking, final_marking = process_tree_converter.apply(process_tree)

""">> #### Evaluation"""

# Perform token-based replay fitness evaluation
fitness = pm4py.fitness_token_based_replay(filtered_log, net, initial_marking, final_marking)

# Perform token-based replay precision evaluation
prec = pm4py.precision_token_based_replay(filtered_log, net, initial_marking, final_marking)

# Perform generalization evaluation
gen = generalization_evaluator.apply(filtered_log, net, initial_marking, final_marking)

# Perform simplicity evaluation
simp = simplicity_evaluator.apply(net)

# Print the evaluation results
print(fitness, " | ", prec, " | ", gen, " | ", simp)

""">> #### Conformance Checking"""

# Replay fitness
replayed_traces = token_replay.apply(filtered_log, net, initial_marking, final_marking)
for trace in replayed_traces:
    print(trace)

# conformance checking - alignments
# aligned_traces = alignments.apply_log(filtered_log, net, initial_marking, final_marking)
# pretty_print_alignments(aligned_traces)